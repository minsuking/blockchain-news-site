import os
import re
import json
from datetime import datetime
from urllib.parse import urlparse, urljoin

import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from openai import OpenAI

# ===== í™˜ê²½ ë³€ìˆ˜(.env) ë¡œë“œ & OpenAI í´ë¼ì´ì–¸íŠ¸ =====
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ===== ì„¤ì • =====
WP_API_BASE = os.getenv("WP_API_BASE")  # ì˜ˆ: https://ë„ë©”ì¸/wp-json/wp/v2/posts
CONTENT_BASE = "content/news"
IMAGE_BASE = "static/images/news"
DEFAULT_CATEGORY = "ë¸”ë¡ì²´ì¸"           # ğŸ”¹ ì¹´í…Œê³ ë¦¬ ê³ ì •
TIME_SUFFIX = "T09:00:00+09:00"         # í•œêµ­ ì‹œê°„ ê¸°ì¤€ ê³ ì •
MAX_POSTS = 100                          # ìµœëŒ€ ê°€ì ¸ì˜¬ í¬ìŠ¤íŠ¸ ìˆ˜
PER_PAGE = 50                           # WP API per_page ìµœëŒ€ 100
# =================


def slugify(text: str) -> str:
    """ì œëª© ê¸°ë°˜ slug ìƒì„± (í•œê¸€+ì˜ë¬¸+ìˆ«ìë§Œ, ê³µë°±ì€ -)"""
    text = text.strip().lower()
    text = re.sub(r"[^a-z0-9ê°€-í£\- ]", "", text)
    text = text.replace(" ", "-")
    return text[:60]


def ensure_dir(path: str):
    if not os.path.exists(path):
        os.makedirs(path, exist_ok=True)


def clean_html_to_markdown(html: str) -> str:
    """ë³¸ë¬¸ HTML ìµœì†Œ ì •ë¦¬"""
    soup = BeautifulSoup(html, "html.parser")

    for br in soup.find_all(["br", "hr"]):
        br.replace_with("\n")

    text = soup.get_text("\n")
    lines = [line.strip() for line in text.splitlines()]
    lines = [line for line in lines if line]
    return "\n\n".join(lines)


def extract_first_image_from_html(html: str, base_url: str | None = None) -> str | None:
    """content.rendered ì•ˆì— <img>ê°€ ìˆì„ ê²½ìš° ì²« ì´ë¯¸ì§€ ë°˜í™˜"""
    soup = BeautifulSoup(html, "html.parser")
    img = soup.find("img")
    if img and img.get("src"):
        src = img["src"]
        if base_url and (src.startswith("/") or not src.startswith("http")):
            return urljoin(base_url, src)
        return src
    return None


def extract_featured_image_from_post(post: dict, content_html: str, base_url: str | None = None) -> str | None:
    """
    1ìˆœìœ„: REST APIì˜ _embedded.wp:featuredmedia.source_url
    2ìˆœìœ„: content.rendered ì•ˆì˜ ì²« ë²ˆì§¸ <img>
    """
    try:
        embedded = post.get("_embedded", {})
        media_list = embedded.get("wp:featuredmedia")
        if isinstance(media_list, list) and media_list:
            media = media_list[0]
            url = media.get("source_url")
            if not url:
                url = (
                    media.get("media_details", {})
                    .get("sizes", {})
                    .get("full", {})
                    .get("source_url")
                )
            if url:
                return url
    except Exception:
        pass

    # fallback: content ì•ˆì—ì„œ <img> ì°¾ê¸°
    return extract_first_image_from_html(content_html, base_url)


def rewrite_with_openai(title: str, content: str) -> tuple[str, str]:
    """
    ì œëª© + ë³¸ë¬¸ì„ OpenAIë¡œ ì¬ì‘ì„±í•˜ì—¬ (ìƒˆ ì œëª©, ìƒˆ ë³¸ë¬¸) ë°˜í™˜
    """
    prompt = f"""
ë‹¤ìŒ ì½˜í…ì¸ ë¥¼ SEOì— ìœ ë¦¬í•œ í•œêµ­ì–´ ë‰´ìŠ¤ ê¸°ì‚¬ í˜•ì‹ìœ¼ë¡œ ì œëª©ê³¼ ë³¸ë¬¸ì„ ëª¨ë‘ ì¬ì‘ì„±í•´ì¤˜.

[ì›ë˜ ì œëª©]
{title}

[ì›ë˜ ë³¸ë¬¸]
{content}

ìš”êµ¬ì‚¬í•­:
- ì œëª©ì€ í´ë¦­ë¥ (CTR)ì´ ë†’ì€ í˜•ì‹ìœ¼ë¡œ 'ìƒˆë¡­ê²Œ' ì¬ì°½ì‘í•  ê²ƒ
- ì›ë˜ ì œëª©ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì§€ ë§ê³ , ë°˜ë“œì‹œ ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ë°”ê¿€ ê²ƒ
- ë³¸ë¬¸ì€ ë¸”ë¡œê·¸ìš© ë‰´ìŠ¤ í†¤ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ
- ë¬¸ì¥ ê¸¸ì´ëŠ” ì›ë¬¸ê³¼ í¬ê²Œ ì°¨ì´ë‚˜ì§€ ì•Šê²Œ
- ì¤‘ë³µ ë¬¸ì¥ ì œê±°
- ë¶ˆí•„ìš”í•œ ë§íˆ¬(ë„ˆë¬´ ìºì£¼ì–¼ X)
- 'ê¸°ì ìŠ¤íƒ€ì¼ + ìš”ì•½ + ë¶€ë“œëŸ¬ìš´ í•´ì„' í†¤

ë°˜í™˜ í˜•ì‹(JSON) ì˜ˆì‹œ:
{{
  "title": "ìƒˆ ì œëª©",
  "content": "ì¬ì‘ì„±ëœ ë³¸ë¬¸"
}}
"""

    try:
        resp = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
        )

        msg = resp.choices[0].message

        # ğŸ”§ ì—¬ê¸°ì„œëŠ” json ë¬¸ìì—´ì´ contentë¡œ ì˜¨ë‹¤ê³  ê°€ì •í•˜ê³  íŒŒì‹±
        if isinstance(msg.content, list):
            content_str = "".join(
                getattr(part, "text", str(part)) for part in msg.content
            )
        else:
            content_str = msg.content

        data = json.loads(content_str)

        new_title = data.get("title", title).strip()
        new_content = data.get("content", content).strip()

        # ëª¨ë¸ì´ ì›ì œëª© ê·¸ëŒ€ë¡œ ëŒë ¤ì£¼ë©´ ê°•ì œë¡œ ì¡°ê¸ˆ ë°”ê¿”ì£¼ê¸°
        if new_title == title:
            new_title = f"{title}â€¦ ì „ë§ê³¼ ë¦¬ìŠ¤í¬ ì´ì •ë¦¬"

        return new_title, new_content

    except Exception as e:
        print("[WARN] OpenAI ì¬ì‘ì„± ì‹¤íŒ¨:", e)
        return title, content


def fetch_wp_posts(max_posts: int = MAX_POSTS, per_page: int = PER_PAGE) -> list[dict]:
    """
    WP REST APIì—ì„œ posts JSONì„ ìµœëŒ€ max_postsê¹Œì§€ ê°€ì ¸ì˜¨ë‹¤.
    _embed=1ì„ ë¶™ì—¬ì„œ ëŒ€í‘œ ì´ë¯¸ì§€ ì •ë³´ê¹Œì§€ ê°€ì ¸ì˜¨ë‹¤.
    """
    collected: list[dict] = []
    page = 1

    if not WP_API_BASE:
        raise RuntimeError("WP_API_BASE í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

    while len(collected) < max_posts:
        params = {"per_page": per_page, "page": page, "_embed": "1"}
        print(f"[INFO] WP posts ìš”ì²­: page={page}, per_page={per_page}")
        resp = requests.get(WP_API_BASE, params=params, timeout=10)

        if resp.status_code != 200:
            print(f"[WARN] WP API ìš”ì²­ ì‹¤íŒ¨ status={resp.status_code}")
            break

        items = resp.json()
        if not items:
            print("[INFO] ë” ì´ìƒ ê°€ì ¸ì˜¬ í¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            break

        collected.extend(items)
        if len(items) < per_page:
            break

        page += 1

    return collected[:max_posts]


def main():
    print(f"[INFO] WP JSONì—ì„œ í¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ëŠ” ì¤‘: {WP_API_BASE}")
    posts = fetch_wp_posts(MAX_POSTS, PER_PAGE)
    print(f"[INFO] ì´ ê°€ì ¸ì˜¨ í¬ìŠ¤íŠ¸ ìˆ˜: {len(posts)}")

    for post in posts:
        # ì› ì œëª©
        raw_title = post.get("title", {}).get("rendered", "") or "ì œëª© ì—†ìŒ"
        orig_title = BeautifulSoup(raw_title, "html.parser").get_text().strip()

        # ë§í¬ (ì´ë¯¸ì§€ ì ˆëŒ€ ê²½ë¡œ ê³„ì‚°ì—ë§Œ ì‚¬ìš©)
        link = post.get("link", "").strip()

        # ë‚ ì§œ
        raw_date = post.get("date") or post.get("date_gmt") or ""
        try:
            dt = datetime.fromisoformat(raw_date.replace("Z", ""))
        except Exception:
            dt = datetime.now()

        date_str = dt.strftime("%Y-%m-%d")
        year = dt.strftime("%Y")
        month = dt.strftime("%m")

        # slug (ì›ë˜ ì œëª© ê¸°ì¤€ìœ¼ë¡œ ë§Œë“œëŠ” ê²Œ ì•ˆì „)
        slug_base = slugify(orig_title) or "untitled"
        slug = f"{date_str}-{slug_base}"

        # ê²½ë¡œ
        content_dir = os.path.join(CONTENT_BASE, year, month)
        ensure_dir(content_dir)
        md_path = os.path.join(content_dir, f"{slug}.md")

        if os.path.exists(md_path):
            print(f"[SKIP] ì´ë¯¸ ì¡´ì¬: {md_path}")
            continue

        # ë³¸ë¬¸ HTML
        raw_content_html = (
            post.get("content", {}).get("rendered", "")
            or post.get("excerpt", {}).get("rendered", "")
            or ""
        )

        body_text = clean_html_to_markdown(raw_content_html)

        # ğŸ”¹ OpenAIë¡œ ì œëª©+ë³¸ë¬¸ ì¬ì‘ì„±
        new_title, new_body = rewrite_with_openai(orig_title, body_text)
        title = new_title
        body_text = new_body
        print(f"[AI] ì œëª© ì¬ì‘ì„±: '{orig_title}'  â†’  '{title}'")

        # ğŸ”¹ ëŒ€í‘œ ì´ë¯¸ì§€ ì¶”ì¶œ (REST API + fallback)
        img_url = extract_featured_image_from_post(post, raw_content_html, base_url=link)
        featured_image = ""

        if img_url:
            try:
                parsed = urlparse(img_url)
                ext = os.path.splitext(parsed.path)[1]
                if ext.lower() not in [".jpg", ".jpeg", ".png", ".webp"]:
                    ext = ".jpg"

                img_dir = os.path.join(IMAGE_BASE, year, month)
                ensure_dir(img_dir)
                img_filename = slug + ext
                img_path = os.path.join(img_dir, img_filename)

                print(f"[IMG] ë‹¤ìš´ë¡œë“œ: {img_url} -> {img_path}")

                headers = {
                    "User-Agent": (
                        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                        "AppleWebKit/537.36 (KHTML, like Gecko) "
                        "Chrome/120.0.0.0 Safari/537.36"
                    )
                }
                r = requests.get(img_url, headers=headers, timeout=10)
                print(f"[IMG] status={r.status_code}")

                if r.status_code == 200:
                    with open(img_path, "wb") as f:
                        f.write(r.content)
                    # Newsroom í…Œë§ˆìš©: image: "news/2025/11/íŒŒì¼ëª…"
                    featured_image = f"news/{year}/{month}/{img_filename}"
                else:
                    print(f"[WARN] ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ status={r.status_code}")
            except Exception as e:
                print(f"[WARN] ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        # front matter
        safe_title = title.replace('"', '\\"')

        front_matter = "---\n"
        front_matter += f'title: "{safe_title}"\n'
        front_matter += f"date: {date_str}{TIME_SUFFIX}\n"
        front_matter += f"lastmod: {date_str}{TIME_SUFFIX}\n"
        front_matter += "draft: false\n"
        front_matter += f'categories: ["{DEFAULT_CATEGORY}"]\n'
        front_matter += "tags: []\n"
        front_matter += 'summary: ""\n'
        if featured_image:
            front_matter += f'image: "{featured_image}"\n'
        front_matter += "---\n\n"

        full_content = front_matter + body_text + "\n"

        with open(md_path, "w", encoding="utf-8") as f:
            f.write(full_content)

        print(f"[OK] ìƒì„±: {md_path}")

    print("[DONE] WP JSON â†’ Hugo ë³€í™˜ ì™„ë£Œ")


if __name__ == "__main__":
    main()
