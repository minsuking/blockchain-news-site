import os
import re
import json
from datetime import datetime
from urllib.parse import urlparse, urljoin

import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from openai import OpenAI

# ===== í™˜ê²½ ë³€ìˆ˜(.env) ë¡œë“œ & OpenAI í´ë¼ì´ì–¸íŠ¸ =====
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ===== ì„¤ì • =====
WP_API_BASE = os.getenv("WP_API_BASE")  # ì˜ˆ: https://ë„ë©”ì¸/wp-json/wp/v2/posts
CONTENT_BASE = "content/news"
IMAGE_BASE = "static/images/news"
DEFAULT_CATEGORY = "ë¸”ë¡ì²´ì¸"           # ğŸ”¹ ì¹´í…Œê³ ë¦¬ ê³ ì •
TIME_SUFFIX = "T09:00:00+09:00"         # í•œêµ­ ì‹œê°„ ê¸°ì¤€ ê³ ì •
MAX_POSTS = 100                          # ìµœëŒ€ ê°€ì ¸ì˜¬ í¬ìŠ¤íŠ¸ ìˆ˜
PER_PAGE = 50                           # WP API per_page ìµœëŒ€ 100
# =================


def slugify(text: str) -> str:
    """ì œëª© ê¸°ë°˜ slug ìƒì„± (í•œê¸€+ì˜ë¬¸+ìˆ«ìë§Œ, ê³µë°±ì€ -)"""
    text = text.strip().lower()
    text = re.sub(r"[^a-z0-9ê°€-í£\- ]", "", text)
    text = text.replace(" ", "-")
    return text[:60]


def ensure_dir(path: str):
    if not os.path.exists(path):
        os.makedirs(path, exist_ok=True)


def clean_html_to_markdown(html: str) -> str:
    """ë³¸ë¬¸ HTML ìµœì†Œ ì •ë¦¬"""
    soup = BeautifulSoup(html, "html.parser")

    for br in soup.find_all(["br", "hr"]):
        br.replace_with("\n")

    text = soup.get_text("\n")
    lines = [line.strip() for line in text.splitlines()]
    lines = [line for line in lines if line]
    return "\n\n".join(lines)


def extract_first_image_from_html(html: str, base_url: str | None = None) -> str | None:
    """content.rendered ì•ˆì— <img>ê°€ ìˆì„ ê²½ìš° ì²« ì´ë¯¸ì§€ ë°˜í™˜"""
    soup = BeautifulSoup(html, "html.parser")
    img = soup.find("img")
    if img and img.get("src"):
        src = img["src"]
        if base_url and (src.startswith("/") or not src.startswith("http")):
            return urljoin(base_url, src)
        return src
    return None


def extract_featured_image_from_post(post: dict, content_html: str, base_url: str | None = None) -> str | None:
    """
    1ìˆœìœ„: REST APIì˜ _embedded.wp:featuredmedia.source_url
    2ìˆœìœ„: content.rendered ì•ˆì˜ ì²« ë²ˆì§¸ <img>
    """
    try:
        embedded = post.get("_embedded", {})
        media_list = embedded.get("wp:featuredmedia")
        if isinstance(media_list, list) and media_list:
            media = media_list[0]
            url = media.get("source_url")
            if not url:
                url = (
                    media.get("media_details", {})
                    .get("sizes", {})
                    .get("full", {})
                    .get("source_url")
                )
            if url:
                return url
    except Exception:
        pass

    # fallback: content ì•ˆì—ì„œ <img> ì°¾ê¸°
    return extract_first_image_from_html(content_html, base_url)


def rewrite_with_openai(title: str, content: str) -> tuple[str, str]:
    """
    ë‰´ìŠ¤ ì›ë¬¸ì„ ì°¸ê³ ìë£Œë¡œ ì‚¬ìš©í•˜ì—¬
    ë¸”ë¡œê·¸í˜• í•´ì„¤ + ê°œì¸ ì˜ê²¬ì´ í¬í•¨ëœ ê¸€ë¡œ ì¬êµ¬ì„±
    """
    prompt = f"""
ì•„ë˜ ë‰´ìŠ¤ ì½˜í…ì¸ ëŠ” 'ì°¸ê³  ìë£Œ'ì¼ ë¿ì…ë‹ˆë‹¤.
ì›ë¬¸ì„ ê·¸ëŒ€ë¡œ ì¬ì‘ì„±í•˜ê±°ë‚˜ ìš”ì•½í•˜ì§€ ë§ê³ ,
ë¸”ë¡œê·¸ ê¸€ ì‘ì„±ìì˜ ê´€ì ì—ì„œ ìƒˆë¡­ê²Œ í•´ì„í•˜ê³  ì„¤ëª…í•˜ëŠ” ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

[ì°¸ê³  ë‰´ìŠ¤ ì œëª©]
{title}

[ì°¸ê³  ë‰´ìŠ¤ ë‚´ìš©]
{content}

ì‘ì„± ëª©í‘œ:
- ë‰´ìŠ¤ ë³µì œ/ìš”ì•½/ì˜ì—­ âŒ
- ê°œì¸ ë¸”ë¡œê·¸ í•´ì„¤ ê¸€ âœ…
- "ì´ ì´ìŠˆë¥¼ ì´ë ‡ê²Œ ë³¸ë‹¤"ë¼ëŠ” ê´€ì ì´ ë“œëŸ¬ë‚˜ì•¼ í•¨

ê¸€ êµ¬ì„± ê°€ì´ë“œ:
1. ë„ì…ë¶€
   - ìµœê·¼ ì´ìŠˆì— ëŒ€í•œ ê°œì¸ì ì¸ ë¬¸ì œì˜ì‹ ë˜ëŠ” ê´€ì‹¬ í¬ì¸íŠ¸ ì œì‹œ
2. ì´ìŠˆ ì •ë¦¬
   - ë‰´ìŠ¤ ë‚´ìš©ì„ ì§ì ‘ ë² ë¼ì§€ ë§ê³ , í•µì‹¬ ë§¥ë½ë§Œ 'í’€ì´í•˜ë“¯' ì„¤ëª…
3. ê°œì¸ í•´ì„
   - ì´ ì‚¬ì•ˆì´ ì™œ ì¤‘ìš”í•˜ë‹¤ê³  ë³´ëŠ”ì§€
   - ì‹œì¥/ê°œì¸/ë…ìì—ê²Œ ì–´ë–¤ ì˜ë¯¸ê°€ ìˆëŠ”ì§€
4. ë§ˆë¬´ë¦¬
   - ê°œì¸ì ì¸ ì „ë§, ìš°ë ¤, í˜¹ì€ ë…ìì—ê²Œ ë˜ì§€ëŠ” ì§ˆë¬¸

ìŠ¤íƒ€ì¼ ê°€ì´ë“œ:
- 1ì¸ì¹­ ì‹œì  í—ˆìš© ("ê°œì¸ì ìœ¼ë¡œ", "ë‚´ê°€ ë³´ê¸°ì—”" ë“±)
- ê¸°ì ë¬¸ì²´ âŒ
- ë¸”ë¡œê·¸ ì¹¼ëŸ¼ í†¤ â­•
- ë¬¸ì¥ êµ¬ì¡°ëŠ” ì›ë¬¸ê³¼ ì „í˜€ ë‹¬ë¼ì•¼ í•¨
- ë‰´ìŠ¤ ë¬¸ì¥, ìˆ˜ì¹˜, í‘œí˜„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ

SEO ê°€ì´ë“œ:
- ìì—°ìŠ¤ëŸ½ê²Œ í‚¤ì›Œë“œëŠ” ë…¹ì´ë˜
- ê²€ìƒ‰ìš© ë¬¸ì¥ ëŠë‚Œ âŒ
- ì‚¬ëŒ ê¸€ ëŠë‚Œ â­•
- AI í‹° ë‚˜ëŠ” í‘œí˜„ ê¸ˆì§€

ë°˜í™˜ í˜•ì‹(JSON):
{{
  "title": "ë¸”ë¡œê·¸ìš© ìƒˆ ì œëª©",
  "content": "ë¸”ë¡œê·¸ í˜•ì‹ì˜ ë³¸ë¬¸"
}}
"""

    try:
        resp = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
        )

        msg = resp.choices[0].message

        if isinstance(msg.content, list):
            content_str = "".join(
                getattr(part, "text", str(part)) for part in msg.content
            )
        else:
            content_str = msg.content

        data = json.loads(content_str)

        new_title = data.get("title", title).strip()
        new_content = data.get("content", content).strip()

        return new_title, new_content

    except Exception as e:
        print("[WARN] OpenAI ì¬ì‘ì„± ì‹¤íŒ¨:", e)
        return title, content



def fetch_wp_posts(max_posts: int = MAX_POSTS, per_page: int = PER_PAGE) -> list[dict]:
    """
    WP REST APIì—ì„œ posts JSONì„ ìµœëŒ€ max_postsê¹Œì§€ ê°€ì ¸ì˜¨ë‹¤.
    _embed=1ì„ ë¶™ì—¬ì„œ ëŒ€í‘œ ì´ë¯¸ì§€ ì •ë³´ê¹Œì§€ ê°€ì ¸ì˜¨ë‹¤.
    """
    collected: list[dict] = []
    page = 1

    if not WP_API_BASE:
        raise RuntimeError("WP_API_BASE í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

    while len(collected) < max_posts:
        params = {"per_page": per_page, "page": page, "_embed": "1"}
        print(f"[INFO] WP posts ìš”ì²­: page={page}, per_page={per_page}")
        resp = requests.get(WP_API_BASE, params=params, timeout=10)

        if resp.status_code != 200:
            print(f"[WARN] WP API ìš”ì²­ ì‹¤íŒ¨ status={resp.status_code}")
            break

        items = resp.json()
        if not items:
            print("[INFO] ë” ì´ìƒ ê°€ì ¸ì˜¬ í¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            break

        collected.extend(items)
        if len(items) < per_page:
            break

        page += 1

    return collected[:max_posts]


def main():
    print(f"[INFO] WP JSONì—ì„œ í¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ëŠ” ì¤‘: {WP_API_BASE}")
    posts = fetch_wp_posts(MAX_POSTS, PER_PAGE)
    print(f"[INFO] ì´ ê°€ì ¸ì˜¨ í¬ìŠ¤íŠ¸ ìˆ˜: {len(posts)}")

    for post in posts:
        # ì› ì œëª©
        raw_title = post.get("title", {}).get("rendered", "") or "ì œëª© ì—†ìŒ"
        orig_title = BeautifulSoup(raw_title, "html.parser").get_text().strip()

        # ë§í¬ (ì´ë¯¸ì§€ ì ˆëŒ€ ê²½ë¡œ ê³„ì‚°ì—ë§Œ ì‚¬ìš©)
        link = post.get("link", "").strip()

        # ë‚ ì§œ
        raw_date = post.get("date") or post.get("date_gmt") or ""
        try:
            dt = datetime.fromisoformat(raw_date.replace("Z", ""))
        except Exception:
            dt = datetime.now()

        date_str = dt.strftime("%Y-%m-%d")
        year = dt.strftime("%Y")
        month = dt.strftime("%m")

        # slug (ì›ë˜ ì œëª© ê¸°ì¤€ìœ¼ë¡œ ë§Œë“œëŠ” ê²Œ ì•ˆì „)
        slug_base = slugify(orig_title) or "untitled"
        slug = f"{date_str}-{slug_base}"

        # ê²½ë¡œ
        content_dir = os.path.join(CONTENT_BASE, year, month)
        ensure_dir(content_dir)
        md_path = os.path.join(content_dir, f"{slug}.md")

        if os.path.exists(md_path):
            print(f"[SKIP] ì´ë¯¸ ì¡´ì¬: {md_path}")
            continue

        # ë³¸ë¬¸ HTML
        raw_content_html = (
            post.get("content", {}).get("rendered", "")
            or post.get("excerpt", {}).get("rendered", "")
            or ""
        )

        body_text = clean_html_to_markdown(raw_content_html)

        # ğŸ”¹ OpenAIë¡œ ì œëª©+ë³¸ë¬¸ ì¬ì‘ì„±
        new_title, new_body = rewrite_with_openai(orig_title, body_text)
        title = new_title
        body_text = new_body
        print(f"[AI] ì œëª© ì¬ì‘ì„±: '{orig_title}'  â†’  '{title}'")

        # ğŸ”¹ ëŒ€í‘œ ì´ë¯¸ì§€ ì¶”ì¶œ (REST API + fallback)
        img_url = extract_featured_image_from_post(post, raw_content_html, base_url=link)
        featured_image = ""

        if img_url:
            try:
                parsed = urlparse(img_url)
                ext = os.path.splitext(parsed.path)[1]
                if ext.lower() not in [".jpg", ".jpeg", ".png", ".webp"]:
                    ext = ".jpg"

                img_dir = os.path.join(IMAGE_BASE, year, month)
                ensure_dir(img_dir)
                img_filename = slug + ext
                img_path = os.path.join(img_dir, img_filename)

                print(f"[IMG] ë‹¤ìš´ë¡œë“œ: {img_url} -> {img_path}")

                headers = {
                    "User-Agent": (
                        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                        "AppleWebKit/537.36 (KHTML, like Gecko) "
                        "Chrome/120.0.0.0 Safari/537.36"
                    )
                }
                r = requests.get(img_url, headers=headers, timeout=10)
                print(f"[IMG] status={r.status_code}")

                if r.status_code == 200:
                    with open(img_path, "wb") as f:
                        f.write(r.content)
                    # Newsroom í…Œë§ˆìš©: image: "news/2025/11/íŒŒì¼ëª…"
                    featured_image = f"news/{year}/{month}/{img_filename}"
                else:
                    print(f"[WARN] ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ status={r.status_code}")
            except Exception as e:
                print(f"[WARN] ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        # front matter
        safe_title = title.replace('"', '\\"')

        front_matter = "---\n"
        front_matter += f'title: "{safe_title}"\n'
        front_matter += f"date: {date_str}{TIME_SUFFIX}\n"
        front_matter += f"lastmod: {date_str}{TIME_SUFFIX}\n"
        front_matter += "draft: false\n"
        front_matter += f'categories: ["{DEFAULT_CATEGORY}"]\n'
        front_matter += "tags: []\n"
        front_matter += 'summary: ""\n'
        if featured_image:
            front_matter += f'image: "{featured_image}"\n'
        front_matter += "---\n\n"

        full_content = front_matter + body_text + "\n"

        with open(md_path, "w", encoding="utf-8") as f:
            f.write(full_content)

        print(f"[OK] ìƒì„±: {md_path}")

    print("[DONE] WP JSON â†’ Hugo ë³€í™˜ ì™„ë£Œ")


if __name__ == "__main__":
    main()
